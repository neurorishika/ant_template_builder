{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segementation Comparision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../verification_data/segmentation_data/training'\n",
    "# get all the filenames\n",
    "filenames = os.listdir(data_dir)\n",
    "# keep only tif files\n",
    "filenames = [f for f in filenames if f.endswith('.nrrd')]\n",
    "# separate into images and labels\n",
    "images = [os.path.join(data_dir, f) for f in filenames if 'segmentation' not in f]\n",
    "labels = [os.path.join(data_dir, f) for f in filenames if 'segmentation' in f]\n",
    "# create a matching list of pairs of images and labels\n",
    "image_to_label = {}\n",
    "label_to_image = {}\n",
    "for image, label in itertools.product(images, labels):\n",
    "    if os.path.splitext(image)[0] == os.path.splitext(label)[0].replace('_segmentation', ''):\n",
    "        image_to_label[image] = label\n",
    "        label_to_image[label] = image\n",
    "# keep only the images that have a label\n",
    "images = list(image_to_label.keys())\n",
    "labels = list(image_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd']\n"
     ]
    }
   ],
   "source": [
    "# Get the templates\n",
    "template_dir = '../verification_data/templates'\n",
    "template_filenames = os.listdir(template_dir)\n",
    "# keep only nrrd files\n",
    "template_filenames = [f for f in template_filenames if f.endswith('.nrrd')]\n",
    "print(template_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target resolution\n",
    "target_resolution = \"0.8x0.8x0.8\" # in microns\n",
    "# get the template with the correct resolution in the name \n",
    "template_filename = [f for f in template_filenames if target_resolution in f]\n",
    "assert len(template_filename) == 1, \"There should be only one template with the target resolution\"\n",
    "template_filename = template_filename[0]\n",
    "# template path\n",
    "template_path = os.path.join(template_dir, template_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying image: ../verification_data/segmentation_data/training/201213_2-6_brain3_LEFT_processed.nrrd\n",
      "The image already exists. Skipping.\n",
      "Mirroring image: ../verification_data/segmentation_data/training/201213_2-1_brain1_RIGHT_processed.nrrd\n",
      "The mirrored image already exists. Skipping.\n",
      "Copying image: ../verification_data/segmentation_data/training/220216_brain10_LEFT_processed.nrrd\n",
      "The image already exists. Skipping.\n",
      "Copying label: ../verification_data/segmentation_data/training/201213_2-6_brain3_LEFT_processed_segmentation.nrrd\n",
      "The label already exists. Skipping.\n",
      "Mirroring label: ../verification_data/segmentation_data/training/201213_2-1_brain1_RIGHT_processed_segmentation.nrrd\n",
      "The mirrored label already exists. Skipping.\n",
      "Copying label: ../verification_data/segmentation_data/training/220216_brain10_LEFT_processed_segmentation.nrrd\n",
      "The label already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# loop over the images and labels and check if names have LEFT or RIGHT in them\n",
    "# if LEFT, mirror the image and label\n",
    "# if RIGHT, do nothing\n",
    "\n",
    "TARGET_DIRECTION = 'LEFT'\n",
    "\n",
    "new_images = []\n",
    "new_labels = []\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    if ('RIGHT' if TARGET_DIRECTION == 'LEFT' else 'LEFT') in image:\n",
    "        # mirror the image\n",
    "        print(\"Mirroring image: \" + image)\n",
    "        # create a mirrored image at the processed data directory\n",
    "        mirrored_image = os.path.join(processed_data_dir, os.path.basename(image).replace(('RIGHT' if TARGET_DIRECTION == 'LEFT' else 'LEFT'), TARGET_DIRECTION))\n",
    "        # check if the image already exists\n",
    "        if os.path.isfile(mirrored_image) or os.path.isfile(os.path.dirname(mirrored_image)+'/backup/'+os.path.basename(mirrored_image)):\n",
    "            print(\"The mirrored image already exists. Skipping.\")\n",
    "            new_images.append(mirrored_image)\n",
    "            continue\n",
    "        reflection_matrix = os.path.join(processed_data_dir, os.path.basename(image)[:-5] + \"_reflection_matrix.mat\")\n",
    "        # create the command\n",
    "        flip_brain_command1 = \"ImageMath 3 {} ReflectionMatrix {} 0\".format(reflection_matrix, image)\n",
    "        flip_brain_command2 = \"WarpImageMultiTransform 3 {} {} -R {} {}\".format(image, mirrored_image, image, reflection_matrix)\n",
    "        # run the commands\n",
    "        print(flip_brain_command1)\n",
    "        # os.system(flip_brain_command1)\n",
    "        os.system(flip_brain_command1)\n",
    "        print(flip_brain_command2)\n",
    "        # os.system(flip_brain_command2)\n",
    "        os.system(flip_brain_command2)\n",
    "        # change the image name to the mirrored image\n",
    "        new_images.append(mirrored_image)\n",
    "    else:\n",
    "        # copy the image to the processed data directory\n",
    "        print(\"Copying image: \" + image)\n",
    "        new_image = os.path.join(processed_data_dir, os.path.basename(image))\n",
    "        # check if the image already exists\n",
    "        if os.path.isfile(new_image) or os.path.isfile(os.path.dirname(new_image)+'/backup/'+os.path.basename(new_image)):\n",
    "            print(\"The image already exists. Skipping.\")\n",
    "            new_images.append(new_image)\n",
    "            continue\n",
    "        # shutil.copyfile(image, new_image)\n",
    "        os.system(\"cp {} {}\".format(image, new_image))\n",
    "        # change the image name to the copied image\n",
    "        new_images.append(new_image)\n",
    "\n",
    "for label in labels:\n",
    "    if ('RIGHT' if TARGET_DIRECTION == 'LEFT' else 'LEFT') in label:\n",
    "        # mirror the label\n",
    "        print(\"Mirroring label: \" + label)\n",
    "        # create a mirrored label at the processed data directory\n",
    "        mirrored_label = os.path.join(processed_data_dir, os.path.basename(label).replace(('RIGHT' if TARGET_DIRECTION == 'LEFT' else 'LEFT'), TARGET_DIRECTION))\n",
    "        # check if the label already exists\n",
    "        if os.path.isfile(mirrored_label) or os.path.isfile(os.path.dirname(mirrored_label)+'/backup/'+os.path.basename(mirrored_label)):\n",
    "            print(\"The mirrored label already exists. Skipping.\")\n",
    "            new_labels.append(mirrored_label)\n",
    "            continue\n",
    "        reflection_matrix = os.path.join(processed_data_dir, os.path.basename(label)[:-5] + \"_reflection_matrix.mat\")\n",
    "        # create the command\n",
    "        flip_brain_command1 = \"ImageMath 3 {} ReflectionMatrix {} 0\".format(reflection_matrix, label)\n",
    "        flip_brain_command2 = \"WarpImageMultiTransform 3 {} {} -R {} {}\".format(label, mirrored_label, label, reflection_matrix)\n",
    "        # flip_brain_command2 = \"antsApplyTransforms -d 3 -i {} -o {} -t {} -r {}\".format(label, mirrored_label, reflection_matrix, label)\n",
    "        # run the commands\n",
    "        print(flip_brain_command1)\n",
    "        # os.system(flip_brain_command1)\n",
    "        os.system(flip_brain_command1)\n",
    "        print(flip_brain_command2)\n",
    "        # os.system(flip_brain_command2)\n",
    "        os.system(flip_brain_command2)\n",
    "        # change the label name to the mirrored label\n",
    "        new_labels.append(mirrored_label)\n",
    "    else:\n",
    "        # copy the label to the processed data directory\n",
    "        print(\"Copying label: \" + label)\n",
    "        new_label = os.path.join(processed_data_dir, os.path.basename(label))\n",
    "        # check if the label already exists\n",
    "        if os.path.isfile(new_label) or os.path.isfile(os.path.dirname(new_label)+'/backup/'+os.path.basename(new_label)):\n",
    "            print(\"The label already exists. Skipping.\")\n",
    "            new_labels.append(new_label)\n",
    "            continue\n",
    "        # shutil.copyfile(label, new_label)\n",
    "        os.system(\"cp {} {}\".format(label, new_label))\n",
    "        # change the label name to the copied label\n",
    "        new_labels.append(new_label)\n",
    "\n",
    "def run_commands(commands_to_run):\n",
    "    for command in commands_to_run:\n",
    "        # print(command)\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample all of the images\n",
    "if not os.path.isdir(\"{}/backup\".format(processed_data_dir)):\n",
    "    # create the backup subdirectory\n",
    "    command = \"mkdir -p {}/backup\".format(processed_data_dir)\n",
    "    !{command}\n",
    "    command = 'mv {}/*.nrrd {}/backup'.format(processed_data_dir, processed_data_dir)\n",
    "    !{command}\n",
    "    command = 'mv {}/*.mat {}/backup'.format(processed_data_dir, processed_data_dir)\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs: 6\n"
     ]
    }
   ],
   "source": [
    "n_jobs = os.listdir(processed_data_dir+'/backup')\n",
    "# filter only nrrd files\n",
    "n_jobs = [f for f in n_jobs if f.endswith('.nrrd')]\n",
    "n_jobs = len(n_jobs)\n",
    "n_cpu = os.cpu_count()\n",
    "print(\"Number of jobs: {}\".format(n_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JKronauer Lab - Microscopy Image Processing Pipeline\n",
      "===================================================\n",
      "Confocal Resampler by Rishika Mohanta\n",
      "Version 1.1.0\n",
      "\n",
      "Output file processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8.nrrd already exists. Will be overwritten.\n",
      "Output file processed_data/220216_brain10_LEFT_processed_segmentation_resampled_0.8x0.8x0.8.nrrd already exists. Will be overwritten.\n",
      "Output file processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8.nrrd already exists. Will be overwritten.\n",
      "Output file processed_data/201213_2-6_brain3_LEFT_processed_segmentation_resampled_0.8x0.8x0.8.nrrd already exists. Will be overwritten.\n",
      "Output file processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8.nrrd already exists. Will be overwritten.\n",
      "Output file processed_data/201213_2-1_brain1_LEFT_processed_segmentation_resampled_0.8x0.8x0.8.nrrd already exists. Will be overwritten.\n",
      "Resampling file 1 of 6\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 2 of 6\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/220216_brain10_LEFT_processed_segmentation_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/220216_brain10_LEFT_processed_segmentation_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 3 of 6\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 4 of 6\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/201213_2-6_brain3_LEFT_processed_segmentation_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/201213_2-6_brain3_LEFT_processed_segmentation_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 5 of 6\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 6 of 6\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/201213_2-1_brain1_LEFT_processed_segmentation_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/201213_2-1_brain1_LEFT_processed_segmentation_resampled_0.8x0.8x0.8_err.log\n",
      "\u001b[H\u001b[2JRemoving empty log files...\n",
      "All files resampled. Exiting...\n"
     ]
    }
   ],
   "source": [
    "command = f'poetry run python ../../scripts/resample.py -i {processed_data_dir+\"/backup\"} -o {processed_data_dir} -v {target_resolution} -n {min(n_jobs, n_cpu)}'\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add resampled_<target_resolution> to the filenames\n",
    "new_images = [x.replace('.nrrd', '_resampled_{}.nrrd'.format(target_resolution)) for x in new_images]\n",
    "new_labels = [x.replace('.nrrd', '_resampled_{}.nrrd'.format(target_resolution)) for x in new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = new_images\n",
    "labels = new_labels\n",
    "# recreate a matching list of pairs of images and labels\n",
    "image_to_label = {}\n",
    "label_to_image = {}\n",
    "for image, label in itertools.product(images, labels):\n",
    "    if os.path.splitext(image)[0] == os.path.splitext(label)[0].replace('_segmentation', ''):\n",
    "        image_to_label[image] = label\n",
    "        label_to_image[label] = image\n",
    "# keep only the images that have a label\n",
    "images = list(image_to_label.keys())\n",
    "labels = list(image_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8.nrrd',\n",
       " 'processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8.nrrd',\n",
       " 'processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8.nrrd']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsIntroduction.sh -d 3 -r /media/DATA01/Rishika/ant_template_builder/verification/verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -i /media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8.nrrd -o /media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8_ -t GR -s CC -m 30x90x20x8 -n 1 -q 1 >/media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8_.log 2>/media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-6_brain3_LEFT_processed_resampled_0.8x0.8x0.8_.err\n",
      "antsIntroduction.sh -d 3 -r /media/DATA01/Rishika/ant_template_builder/verification/verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -i /media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8.nrrd -o /media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8_ -t GR -s CC -m 30x90x20x8 -n 1 -q 1 >/media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8_.log 2>/media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/201213_2-1_brain1_LEFT_processed_resampled_0.8x0.8x0.8_.err\n",
      "antsIntroduction.sh -d 3 -r /media/DATA01/Rishika/ant_template_builder/verification/verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -i /media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8.nrrd -o /media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8_ -t GR -s CC -m 30x90x20x8 -n 1 -q 1 >/media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8_.log 2>/media/DATA01/Rishika/ant_template_builder/verification/segmentation/processed_data/220216_brain10_LEFT_processed_resampled_0.8x0.8x0.8_.err\n"
     ]
    }
   ],
   "source": [
    "# loop over the images and register them to the template using ANTs\n",
    "# loop over the images\n",
    "for image in images:\n",
    "    # generate output prefix\n",
    "    output_prefix = os.path.basename(image).replace('.nrrd', '_')\n",
    "    output_prefix = os.path.join(processed_data_dir, output_prefix)\n",
    "    # check if files with this prefix already exist\n",
    "    if os.path.isfile(output_prefix + 'Warped.nii.gz'):\n",
    "        print(\"The registered image already exists. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # convert template path to full path\n",
    "    template_path_ = os.path.abspath(template_path)\n",
    "    # convert image path to full path\n",
    "    image_ = os.path.abspath(image)\n",
    "    # convert output prefix to full path\n",
    "    output_prefix_ = os.path.abspath(output_prefix)\n",
    "\n",
    "\n",
    "    # create registration command\n",
    "    command = f'antsIntroduction.sh -d 3 -r {template_path_} -i {image_} '\n",
    "    command += f'-o {output_prefix_} -t GR -s CC -m 30x90x20x8 -n 1 -q 1 '\n",
    "    command += f'>{output_prefix_}.log 2>{output_prefix_}.err'\n",
    "    # add the command to the list of commands\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsApplyTransforms -d 3 -i processed_data/201213_2-6_brain3_RIGHT_processed_segmentation.nrrd -r ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -o processed_data/warped_201213_2-6_brain3_RIGHT_processed_segmentation_.nrrd -n GenericLabel -t processed_data/201213_2-6_brain3_RIGHT_processed_1Warp.nii.gz -t processed_data/201213_2-6_brain3_RIGHT_processed_0GenericAffine.mat >processed_data/warped_201213_2-6_brain3_RIGHT_processed_segmentation_.log 2>processed_data/warped_201213_2-6_brain3_RIGHT_processed_segmentation_.err\n",
      "antsApplyTransforms -d 3 -i processed_data/201213_2-1_brain1_RIGHT_processed_segmentation.nrrd -r ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -o processed_data/warped_201213_2-1_brain1_RIGHT_processed_segmentation_.nrrd -n GenericLabel -t processed_data/201213_2-1_brain1_RIGHT_processed_1Warp.nii.gz -t processed_data/201213_2-1_brain1_RIGHT_processed_0GenericAffine.mat >processed_data/warped_201213_2-1_brain1_RIGHT_processed_segmentation_.log 2>processed_data/warped_201213_2-1_brain1_RIGHT_processed_segmentation_.err\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsApplyTransforms -d 3 -i processed_data/220216_brain10_RIGHT_processed_segmentation.nrrd -r ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -o processed_data/warped_220216_brain10_RIGHT_processed_segmentation_.nrrd -n GenericLabel -t processed_data/220216_brain10_RIGHT_processed_1Warp.nii.gz -t processed_data/220216_brain10_RIGHT_processed_0GenericAffine.mat >processed_data/warped_220216_brain10_RIGHT_processed_segmentation_.log 2>processed_data/warped_220216_brain10_RIGHT_processed_segmentation_.err\n"
     ]
    }
   ],
   "source": [
    "# loop over the labels and warp them to the template using the generated transforms during registration\n",
    "\n",
    "for label in labels:\n",
    "    # generate output prefix\n",
    "    output_prefix = os.path.basename(label).replace('.nrrd', '_')\n",
    "    output_prefix = processed_data_dir + '/warped_' + output_prefix\n",
    "    # get the corresponding image\n",
    "    image = label_to_image[label]\n",
    "    # get the corresponding output prefix\n",
    "    image_output_prefix = os.path.basename(image).replace('.nrrd', '_')\n",
    "    image_output_prefix = processed_data_dir + '/' + image_output_prefix\n",
    "    # convert template path to full path\n",
    "    template_path_ = os.path.abspath(template_path)\n",
    "    # convert label path to full path\n",
    "    label_ = os.path.abspath(label)\n",
    "    # convert output prefix to full path\n",
    "    output_prefix_ = os.path.abspath(output_prefix)\n",
    "    # convert image path to full path\n",
    "    image_output_prefix_ = os.path.abspath(image_output_prefix)\n",
    "    # create registration command\n",
    "    command = f'WarpImageMultiTransform 3 {label_} {output_prefix_}segmented.nrrd -R {template_path_} '\n",
    "    command += f'{image_output_prefix_}Warp.nii.gz {image_output_prefix_}Affine.txt '\n",
    "    command += f'>{output_prefix_}.log 2>{output_prefix_}.err'\n",
    "    # command = f'antsApplyTransforms -d 3 -i {label} -r {template_path}'\n",
    "    # command += f' -o {output_prefix}.nrrd -n GenericLabel -t {image_output_prefix}1Warp.nii.gz'\n",
    "    # command += f' -t {image_output_prefix}0GenericAffine.mat >{output_prefix}.log 2>{output_prefix}.err'\n",
    "    # add the command to the list of commands\n",
    "    print(command)\n",
    "    os.system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the warped labels using pynrrd and save them as numpy arrays\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "final_labels = []\n",
    "final_labels_paths = []\n",
    "\n",
    "# loop over the labels\n",
    "for label in labels:\n",
    "    # generate output prefix\n",
    "    output_prefix = os.path.basename(label).replace('.nrrd', '_')\n",
    "    output_prefix = processed_data_dir + '/warped_' + output_prefix\n",
    "    # open the label using pynrrd\n",
    "    label_data, label_header = nrrd.read(output_prefix + '.nrrd')\n",
    "    final_labels.append(label_data)\n",
    "    final_labels_paths.append(output_prefix + '.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each final label, sort the unique values map them to the values 0, 1, 2, ...\n",
    "n_channels = []\n",
    "\n",
    "for i, label in enumerate(final_labels):\n",
    "    processed_label = label.copy()\n",
    "    # get the unique values\n",
    "    unique_values = np.unique(label)\n",
    "    # sort the unique values\n",
    "    unique_values.sort()\n",
    "    # append the number of channels to the list\n",
    "    n_channels.append(len(unique_values))\n",
    "    # map the unique values to the values 0, 1, 2, ...\n",
    "    for j, value in enumerate(unique_values):\n",
    "        processed_label[label == value] = j\n",
    "    # save the label as a numpy array\n",
    "    np.save(final_labels_paths[i], label)\n",
    "\n",
    "# assert that all the labels have the same number of channels\n",
    "assert len(set(n_channels)) == 1, \"All the labels should have the same number of channels\"\n",
    "\n",
    "# create the channel wise labels\n",
    "channel_wise_labels = []\n",
    "n_channels = n_channels[0]\n",
    "\n",
    "# loop over the channels\n",
    "for i in range(n_channels):\n",
    "    channel_wise_labels.append([label == i for label in final_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_volume(vol1, vol2):\n",
    "    \"\"\"\n",
    "    Computes the Dice volume overlap between two volumes.\n",
    "    \"\"\"\n",
    "    return 2 * np.sum(np.logical_and(vol1, vol2)) / (np.sum(vol1) + np.sum(vol2))\n",
    "\n",
    "def pairwise_dice_volume(vols):\n",
    "    \"\"\"\n",
    "    Computes the Dice volume overlap between all pairs of volumes.\n",
    "    \"\"\"\n",
    "    n_vols = len(vols)\n",
    "    dice_volumes = np.ones((n_vols, n_vols))*np.nan\n",
    "    for i in range(n_vols):\n",
    "        for j in range(i+1, n_vols):\n",
    "            dice_volumes[i, j] = dice_volume(vols[i], vols[j])\n",
    "    return dice_volumes\n",
    "\n",
    "# compute the pairwise dice volume for each channel\n",
    "dice_volumes = []\n",
    "for channel in channel_wise_labels:\n",
    "    dice_volumes.append(pairwise_dice_volume(channel))\n",
    "\n",
    "# save the dice volumes\n",
    "np.save(processed_data_dir + '/dice_volumes.npy', dice_volumes)\n",
    "\n",
    "# compute the average dice volume for each channel\n",
    "for i, channel in enumerate(dice_volumes):\n",
    "    # remove the NaNs\n",
    "    channel_ = channel[~np.isnan(channel)].flatten()\n",
    "    # compute the statistics\n",
    "    print('Channel {}'.format(i))\n",
    "    print('==========')\n",
    "    print(\"Average Dice volume: {:.2f}\".format(np.mean(channel_)))\n",
    "    print(\"Median Dice volume: {:.2f}\".format(np.median(channel_)))\n",
    "    print(\"95% CI: ({:.2f}, {:.2f})\".format(np.percentile(channel_, 2.5), np.percentile(channel_, 97.5)))\n",
    "    print(\"Min: {:.2f}\".format(np.min(channel_)))\n",
    "    print(\"Max: {:.2f}\".format(np.max(channel_)))\n",
    "    print(\"Std: {:.2f}\".format(np.std(channel_)))\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
