{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segementation Comparision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../verification_data/segmentation_data/test'\n",
    "# get all the filenames\n",
    "filenames = os.listdir(data_dir)\n",
    "# keep only tif files\n",
    "filenames = [f for f in filenames if f.endswith('.nrrd')]\n",
    "# separate into images and labels\n",
    "images = [os.path.join(data_dir, f) for f in filenames if 'segmentation' not in f]\n",
    "labels = [os.path.join(data_dir, f) for f in filenames if 'segmentation' in f]\n",
    "# create a matching list of pairs of images and labels\n",
    "image_to_label = {}\n",
    "label_to_image = {}\n",
    "for image, label in itertools.product(images, labels):\n",
    "    if os.path.splitext(image)[0] == os.path.splitext(label)[0].replace('_segmentation', ''):\n",
    "        image_to_label[image] = label\n",
    "        label_to_image[label] = image\n",
    "# keep only the images that have a label\n",
    "images = list(image_to_label.keys())\n",
    "labels = list(image_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obiroi_template_20231127_1647_0.4x0.4x0.4.nrrd', 'obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd', 'obiroi_template_20231127_1722_0.2x0.2x0.2.nrrd']\n"
     ]
    }
   ],
   "source": [
    "# Get the templates\n",
    "template_dir = '../verification_data/templates'\n",
    "template_filenames = os.listdir(template_dir)\n",
    "# keep only nrrd files\n",
    "template_filenames = [f for f in template_filenames if f.endswith('.nrrd')]\n",
    "print(template_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target resolution\n",
    "target_resolution = \"0.8x0.8x0.8\" # in microns\n",
    "# get the template with the correct resolution in the name \n",
    "template_filename = [f for f in template_filenames if target_resolution in f]\n",
    "assert len(template_filename) == 1, \"There should be only one template with the target resolution\"\n",
    "template_filename = template_filename[0]\n",
    "# template path\n",
    "template_path = os.path.join(template_dir, template_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mirroring image: ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed.nrrd\n",
      "ImageMath 3 processed_data/220214_brain3_LEFT_processed_reflection_matrix.mat ReflectionMatrix ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed.nrrd 0\n",
      "antsApplyTransforms -d 3 -i ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed.nrrd -o processed_data/220214_brain3_RIGHT_processed.nrrd -t processed_data/220214_brain3_LEFT_processed_reflection_matrix.mat -r ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed.nrrd\n",
      "Copying image: ../verification_data/segmentation_data/test/LLA4_SYM_processed.nrrd\n",
      "Mirroring label: ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed_segmentation.nrrd\n",
      "ImageMath 3 processed_data/220214_brain3_LEFT_processed_segmentation_reflection_matrix.mat ReflectionMatrix ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed_segmentation.nrrd 0\n",
      "antsApplyTransforms -d 3 -i ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed_segmentation.nrrd -o processed_data/220214_brain3_RIGHT_processed_segmentation.nrrd -t processed_data/220214_brain3_LEFT_processed_segmentation_reflection_matrix.mat -r ../verification_data/segmentation_data/test/220214_brain3_LEFT_processed_segmentation.nrrd\n",
      "Copying label: ../verification_data/segmentation_data/test/LLA4_SYM_processed_segmentation.nrrd\n"
     ]
    }
   ],
   "source": [
    "# loop over the images and labels and check if names have LEFT or RIGHT in them\n",
    "# if LEFT, mirror the image and label\n",
    "# if RIGHT, do nothing\n",
    "new_images = []\n",
    "new_labels = []\n",
    "\n",
    "commands_to_run = []\n",
    "\n",
    "for image in images:\n",
    "    current_command = []\n",
    "    if 'LEFT' in image:\n",
    "        # mirror the image\n",
    "        print(\"Mirroring image: \" + image)\n",
    "        # create a mirrored image at the processed data directory\n",
    "        mirrored_image = os.path.join(processed_data_dir, os.path.basename(image).replace('LEFT', 'RIGHT'))\n",
    "        # check if the image already exists\n",
    "        if os.path.isfile(mirrored_image):\n",
    "            print(\"The mirrored image already exists. Skipping.\")\n",
    "            new_images.append(mirrored_image)\n",
    "            continue\n",
    "        reflection_matrix = os.path.join(processed_data_dir, os.path.basename(image)[:-5] + \"_reflection_matrix.mat\")\n",
    "        # create the command\n",
    "        flip_brain_command1 = \"ImageMath 3 {} ReflectionMatrix {} 0\".format(reflection_matrix, image)\n",
    "        flip_brain_command2 = \"WarpImageMultiTransform 3 {} {} -R {} {}\".format(image, mirrored_image, image, reflection_matrix)\n",
    "        # run the commands\n",
    "        print(flip_brain_command1)\n",
    "        # os.system(flip_brain_command1)\n",
    "        current_command.append(flip_brain_command1)\n",
    "        print(flip_brain_command2)\n",
    "        # os.system(flip_brain_command2)\n",
    "        current_command.append(flip_brain_command2)\n",
    "        # change the image name to the mirrored image\n",
    "        new_images.append(mirrored_image)\n",
    "    else:\n",
    "        # copy the image to the processed data directory\n",
    "        print(\"Copying image: \" + image)\n",
    "        new_image = os.path.join(processed_data_dir, os.path.basename(image))\n",
    "        # check if the image already exists\n",
    "        if os.path.isfile(new_image):\n",
    "            print(\"The image already exists. Skipping.\")\n",
    "            new_images.append(new_image)\n",
    "            continue\n",
    "        # shutil.copyfile(image, new_image)\n",
    "        current_command.append(\"cp {} {}\".format(image, new_image))\n",
    "        # change the image name to the copied image\n",
    "        new_images.append(new_image)\n",
    "    commands_to_run.append(current_command)\n",
    "\n",
    "for label in labels:\n",
    "    current_command = []\n",
    "    if 'LEFT' in label:\n",
    "        # mirror the label\n",
    "        print(\"Mirroring label: \" + label)\n",
    "        # create a mirrored label at the processed data directory\n",
    "        mirrored_label = os.path.join(processed_data_dir, os.path.basename(label).replace('LEFT', 'RIGHT'))\n",
    "        # check if the label already exists\n",
    "        if os.path.isfile(mirrored_label):\n",
    "            print(\"The mirrored label already exists. Skipping.\")\n",
    "            new_labels.append(mirrored_label)\n",
    "            continue\n",
    "        reflection_matrix = os.path.join(processed_data_dir, os.path.basename(label)[:-5] + \"_reflection_matrix.mat\")\n",
    "        # create the command\n",
    "        flip_brain_command1 = \"ImageMath 3 {} ReflectionMatrix {} 0\".format(reflection_matrix, label)\n",
    "        flip_brain_command2 = \"WarpImageMultiTransform 3 {} {} -R {} {}\".format(label, mirrored_label, label, reflection_matrix)\n",
    "        # flip_brain_command2 = \"antsApplyTransforms -d 3 -i {} -o {} -t {} -r {}\".format(label, mirrored_label, reflection_matrix, label)\n",
    "        # run the commands\n",
    "        print(flip_brain_command1)\n",
    "        # os.system(flip_brain_command1)\n",
    "        current_command.append(flip_brain_command1)\n",
    "        print(flip_brain_command2)\n",
    "        # os.system(flip_brain_command2)\n",
    "        current_command.append(flip_brain_command2)\n",
    "        # change the label name to the mirrored label\n",
    "        new_labels.append(mirrored_label)\n",
    "    else:\n",
    "        # copy the label to the processed data directory\n",
    "        print(\"Copying label: \" + label)\n",
    "        new_label = os.path.join(processed_data_dir, os.path.basename(label))\n",
    "        # check if the label already exists\n",
    "        if os.path.isfile(new_label):\n",
    "            print(\"The label already exists. Skipping.\")\n",
    "            new_labels.append(new_label)\n",
    "            continue\n",
    "        # shutil.copyfile(label, new_label)\n",
    "        current_command.append(\"cp {} {}\".format(label, new_label))\n",
    "        # change the label name to the copied label\n",
    "        new_labels.append(new_label)\n",
    "    commands_to_run.append(current_command)\n",
    "\n",
    "def run_commands(commands_to_run):\n",
    "    for command in commands_to_run:\n",
    "        # print(command)\n",
    "        os.system(command)\n",
    "\n",
    "# get CPU count using os\n",
    "n_cpu = os.cpu_count()\n",
    "\n",
    "# run the commands in parallel\n",
    "from joblib import Parallel, delayed\n",
    "_ = Parallel(n_jobs=n_cpu)(delayed(run_commands)(commands) for commands in commands_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample all of the images\n",
    "if os.path.isdir(\"{}/backup\".format(processed_data_dir)):\n",
    "    command = \"rm -rf {}/backup\".format(processed_data_dir)\n",
    "    !{command}\n",
    "# create the backup subdirectory\n",
    "command = \"mkdir -p {}/backup\".format(processed_data_dir)\n",
    "!{command}\n",
    "command = 'mv {}/*.nrrd {}/backup'.format(processed_data_dir, processed_data_dir)\n",
    "!{command}\n",
    "command = 'mv {}/*.mat {}/backup'.format(processed_data_dir, processed_data_dir)\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs: 4\n"
     ]
    }
   ],
   "source": [
    "n_jobs = os.listdir(processed_data_dir+'/backup')\n",
    "# filter only nrrd files\n",
    "n_jobs = [f for f in n_jobs if f.endswith('.nrrd')]\n",
    "n_jobs = len(n_jobs)\n",
    "print(\"Number of jobs: {}\".format(n_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JKronauer Lab - Microscopy Image Processing Pipeline\n",
      "===================================================\n",
      "Confocal Resampler by Rishika Mohanta\n",
      "Version 1.1.0\n",
      "\n",
      "Resampling file 1 of 4\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/LLA4_SYM_processed_segmentation_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/LLA4_SYM_processed_segmentation_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 2 of 4\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/220214_brain3_RIGHT_processed_segmentation_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/220214_brain3_RIGHT_processed_segmentation_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 3 of 4\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8_err.log\n",
      "Resampling file 4 of 4\n",
      "Target resolution: 0.8 μm x 0.8 μm x 0.8 μm\n",
      "Log file: processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8_out.log\n",
      "Error file: processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8_err.log\n",
      "\u001b[H\u001b[2JRemoving empty log files...\n",
      "All files resampled. Exiting...\n"
     ]
    }
   ],
   "source": [
    "command = f'poetry run python ../../scripts/resample.py -i {processed_data_dir+\"/backup\"} -o {processed_data_dir} -v {target_resolution} -n {min(n_jobs, n_cpu)}'\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add resampled_<target_resolution> to the filenames\n",
    "new_images = [x.replace('.nrrd', '_resampled_{}.nrrd'.format(target_resolution)) for x in new_images]\n",
    "new_labels = [x.replace('.nrrd', '_resampled_{}.nrrd'.format(target_resolution)) for x in new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = new_images\n",
    "labels = new_labels\n",
    "# recreate a matching list of pairs of images and labels\n",
    "image_to_label = {}\n",
    "label_to_image = {}\n",
    "for image, label in itertools.product(images, labels):\n",
    "    if os.path.splitext(image)[0] == os.path.splitext(label)[0].replace('_segmentation', ''):\n",
    "        image_to_label[image] = label\n",
    "        label_to_image[label] = image\n",
    "# keep only the images that have a label\n",
    "images = list(image_to_label.keys())\n",
    "labels = list(image_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8.nrrd',\n",
       " 'processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8.nrrd']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsRegistrationSyN.sh -d 3 -f ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -m processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8.nrrd -o processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8_ -n 112 -t s -y 1 >processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8_.log 2>processed_data/220214_brain3_RIGHT_processed_resampled_0.8x0.8x0.8_.err\n",
      "antsRegistrationSyN.sh -d 3 -f ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -m processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8.nrrd -o processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8_ -n 112 -t s -y 1 >processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8_.log 2>processed_data/LLA4_SYM_processed_resampled_0.8x0.8x0.8_.err\n"
     ]
    }
   ],
   "source": [
    "# loop over the images and register them to the template using ANTs\n",
    "commands_to_run = []\n",
    "# loop over the images\n",
    "for image in images:\n",
    "    # generate output prefix\n",
    "    output_prefix = os.path.basename(image).replace('.nrrd', '_')\n",
    "    output_prefix = os.path.join(processed_data_dir, output_prefix)\n",
    "    # check if files with this prefix already exist\n",
    "    if os.path.isfile(output_prefix + 'Warped.nii.gz'):\n",
    "        print(\"The registered image already exists. Skipping.\")\n",
    "        continue\n",
    "    # create registration command\n",
    "    command = f'antsIntroduction.sh -d 3 -r {template_path} -i {image} '\n",
    "    command += f'-o {output_prefix} -t GR -s CC -m 30x90x20x8 -n 1 -q 1 '\n",
    "    command += f'>{output_prefix}.log 2>{output_prefix}.err'\n",
    "    # add the command to the list of commands\n",
    "    print(command)\n",
    "    commands_to_run.append(command)\n",
    "\n",
    "# run the commands in parallel\n",
    "from joblib import Parallel, delayed\n",
    "_ = Parallel(n_jobs=n_cpu)(delayed(os.system)(command) for command in commands_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsApplyTransforms -d 3 -i processed_data/201213_2-6_brain3_RIGHT_processed_segmentation.nrrd -r ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -o processed_data/warped_201213_2-6_brain3_RIGHT_processed_segmentation_.nrrd -n GenericLabel -t processed_data/201213_2-6_brain3_RIGHT_processed_1Warp.nii.gz -t processed_data/201213_2-6_brain3_RIGHT_processed_0GenericAffine.mat >processed_data/warped_201213_2-6_brain3_RIGHT_processed_segmentation_.log 2>processed_data/warped_201213_2-6_brain3_RIGHT_processed_segmentation_.err\n",
      "antsApplyTransforms -d 3 -i processed_data/201213_2-1_brain1_RIGHT_processed_segmentation.nrrd -r ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -o processed_data/warped_201213_2-1_brain1_RIGHT_processed_segmentation_.nrrd -n GenericLabel -t processed_data/201213_2-1_brain1_RIGHT_processed_1Warp.nii.gz -t processed_data/201213_2-1_brain1_RIGHT_processed_0GenericAffine.mat >processed_data/warped_201213_2-1_brain1_RIGHT_processed_segmentation_.log 2>processed_data/warped_201213_2-1_brain1_RIGHT_processed_segmentation_.err\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsApplyTransforms -d 3 -i processed_data/220216_brain10_RIGHT_processed_segmentation.nrrd -r ../verification_data/templates/obiroi_template_20231127_1647_0.8x0.8x0.8.nrrd -o processed_data/warped_220216_brain10_RIGHT_processed_segmentation_.nrrd -n GenericLabel -t processed_data/220216_brain10_RIGHT_processed_1Warp.nii.gz -t processed_data/220216_brain10_RIGHT_processed_0GenericAffine.mat >processed_data/warped_220216_brain10_RIGHT_processed_segmentation_.log 2>processed_data/warped_220216_brain10_RIGHT_processed_segmentation_.err\n"
     ]
    }
   ],
   "source": [
    "# loop over the labels and warp them to the template using the generated transforms during registration\n",
    "commands_to_run = []\n",
    "# loop over the labels\n",
    "for label in labels:\n",
    "    # generate output prefix\n",
    "    output_prefix = os.path.basename(label).replace('.nrrd', '_')\n",
    "    output_prefix = processed_data_dir + '/warped_' + output_prefix\n",
    "    # get the corresponding image\n",
    "    image = label_to_image[label]\n",
    "    # get the corresponding output prefix\n",
    "    image_output_prefix = os.path.basename(image).replace('.nrrd', '_')\n",
    "    image_output_prefix = processed_data_dir + '/' + image_output_prefix\n",
    "    # create registration command\n",
    "    command = f'WarpImageMultiTransform 3 {label} {output_prefix}segmented.nrrd -R {template_path} '\n",
    "    command += f'{image_output_prefix}1Warp.nii.gz {image_output_prefix}0GenericAffine.mat '\n",
    "    command += f'>{output_prefix}.log 2>{output_prefix}.err'\n",
    "    # command = f'antsApplyTransforms -d 3 -i {label} -r {template_path}'\n",
    "    # command += f' -o {output_prefix}.nrrd -n GenericLabel -t {image_output_prefix}1Warp.nii.gz'\n",
    "    # command += f' -t {image_output_prefix}0GenericAffine.mat >{output_prefix}.log 2>{output_prefix}.err'\n",
    "    # add the command to the list of commands\n",
    "    print(command)\n",
    "    commands_to_run.append(command)\n",
    "\n",
    "# run the commands in parallel\n",
    "_ = Parallel(n_jobs=n_cpu)(delayed(os.system)(command) for command in commands_to_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the warped labels using pynrrd and save them as numpy arrays\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "final_labels = []\n",
    "final_labels_paths = []\n",
    "\n",
    "# loop over the labels\n",
    "for label in labels:\n",
    "    # generate output prefix\n",
    "    output_prefix = os.path.basename(label).replace('.nrrd', '_')\n",
    "    output_prefix = processed_data_dir + '/warped_' + output_prefix\n",
    "\n",
    "    # open the label using pynrrd\n",
    "    label_data, label_header = nrrd.read(output_prefix + '.nrrd')\n",
    "    # save the label as a numpy array\n",
    "    np.save(output_prefix + '.npy', label_data)\n",
    "\n",
    "    final_labels.append(label_data)\n",
    "    final_labels_paths.append(output_prefix + '.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
